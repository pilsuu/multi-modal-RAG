# multi-modal-RAG

- ref : https://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb
- It covers the process of refining the data to be entered into the vector database
- Specifically, it involves extracting images from PDFs containing images and extracting text from images using OCRs
- be sure you have pdf file to analyze in google drive
- It needs to proceed in linux enviroment. I recommend to run this code in colab
